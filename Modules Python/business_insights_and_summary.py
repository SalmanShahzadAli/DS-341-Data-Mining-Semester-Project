"""
DS341 - DATA MINING PROJECT
Section 8: BUSINESS INSIGHTS, RECOMMENDATIONS & SUMMARY
Synthesize findings and provide actionable insights
"""

import pandas as pd
import numpy as np
from imports_setup import print_section_header, print_subsection_header
from preprocessing import preprocess_complete_pipeline
from dataset_loading import load_dataset, assess_data_quality
from association_rule_mining import perform_association_rule_mining
from classification_models import perform_classification
from clustering_and_segmentation import perform_clustering

# ============================================================================
# ASSOCIATION RULE INSIGHTS
# ============================================================================

def association_rule_insights(rules):
    """
    Generate business insights from association rules
    
    Parameters:
    -----------
    rules : pd.DataFrame
        Association rules
    """
    print_subsection_header("Association Rule Mining Insights")
    
    if rules is None or len(rules) == 0:
        print("  No association rules found")
        return
    
    print(f"\n‚úì Total Rules Generated: {len(rules)}")
    
    if len(rules) > 0:
        top_rule = rules.nlargest(1, 'lift').iloc[0]
        print(f"\nüîù Top Rule by Lift:")
        print(f"   {top_rule['antecedents']} ‚Üí {top_rule['consequents']}")
        print(f"   Confidence: {top_rule['confidence']:.2%}")
        print(f"   Lift: {top_rule['lift']:.2f}")
        print(f"   Interpretation: Customers who buy {top_rule['antecedents']} are")
        print(f"   {top_rule['lift']:.2f}x more likely to buy {top_rule['consequents']}")
    
    # Avg metrics
    print(f"\nüìä Rule Statistics:")
    print(f"   Average Support: {rules['support'].mean():.4f}")
    print(f"   Average Confidence: {rules['confidence'].mean():.4f}")
    print(f"   Average Lift: {rules['lift'].mean():.4f}")
    
    print(f"\nüí° Recommendations:")
    print(f"   1. Use top rules for product bundling strategies")
    print(f"   2. Implement cross-selling based on co-purchase patterns")
    print(f"   3. Place associated products near each other in store/website")
    print(f"   4. Create targeted promotions using these relationships")

# ============================================================================
# CLASSIFICATION INSIGHTS
# ============================================================================

def classification_insights(classification_result):
    """
    Generate business insights from classification models
    
    Parameters:
    -----------
    classification_result : dict
        Classification results
    """
    print_subsection_header("Classification Model Insights")
    
    if classification_result is None:
        print("  Classification not performed")
        return
    
    results = classification_result['results']
    
    # Find best model
    best_model = max(results.items(), key=lambda x: x[1]['f1'])
    
    print(f"\n‚úì Models Trained: {len(results)}")
    print(f"\nüèÜ Best Performing Model: {best_model[0]}")
    print(f"   Accuracy: {best_model[1]['accuracy']:.2%}")
    print(f"   Precision: {best_model[1]['precision']:.2%}")
    print(f"   Recall: {best_model[1]['recall']:.2%}")
    print(f"   F1-Score: {best_model[1]['f1']:.2%}")
    
    print(f"\nüí° Recommendations:")
    print(f"   1. Deploy {best_model[0]} for high-value customer prediction")
    print(f"   2. Use model to identify potential high-value customers")
    print(f"   3. Allocate resources to customers predicted as high-value")
    print(f"   4. Monitor model performance regularly and retrain as needed")
    print(f"   5. Use predictions for targeted marketing campaigns")

# ============================================================================
# CLUSTERING INSIGHTS
# ============================================================================

def clustering_insights(clustering_result, df_original):
    """
    Generate business insights from clustering
    
    Parameters:
    -----------
    clustering_result : dict
        Clustering results
    df_original : pd.DataFrame
        Original dataset
    """
    print_subsection_header("Customer Segmentation Insights")
    
    if clustering_result is None:
        print("  Clustering not performed")
        return
    
    clusters = clustering_result['clusters']
    optimal_k = clustering_result['optimal_k']
    
    print(f"\n‚úì Number of Customer Segments: {optimal_k}")
    
    # Cluster distribution
    unique, counts = np.unique(clusters, return_counts=True)
    print(f"\nüìä Segment Distribution:")
    for cluster_id, count in zip(unique, counts):
        pct = count / len(clusters) * 100
        print(f"   Cluster {cluster_id}: {count} customers ({pct:.1f}%)")
    
    print(f"\nüí° Recommendations:")
    print(f"   1. Develop segment-specific marketing strategies")
    print(f"   2. Tailor product offerings for each segment")
    print(f"   3. Create personalized customer experiences per segment")
    print(f"   4. Allocate marketing budget based on segment value")
    print(f"   5. Monitor segment migration over time")

# ============================================================================
# OVERALL SUMMARY
# ============================================================================

def generate_summary_report(df_original, preprocessing_result, classification_result, 
                           clustering_result, frequent_itemsets, rules):
    """
    Generate comprehensive summary report
    
    Parameters:
    -----------
    df_original : pd.DataFrame
        Original dataset
    preprocessing_result : dict
        Preprocessing results
    classification_result : dict
        Classification results
    clustering_result : dict
        Clustering results
    frequent_itemsets : pd.DataFrame
        Frequent itemsets
    rules : pd.DataFrame
        Association rules
    """
    print_section_header("COMPREHENSIVE PROJECT SUMMARY")
    
    # 1. Dataset Summary
    print_subsection_header("Dataset Summary")
    print(f"   Original Records: {df_original.shape[0]}")
    print(f"   Original Features: {df_original.shape[1]}")
    print(f"   Cleaned Records: {preprocessing_result['final_shape'][0]}")
    print(f"   Records Removed: {df_original.shape[0] - preprocessing_result['final_shape'][0]}")
    print(f"   Removal Rate: {(df_original.shape[0] - preprocessing_result['final_shape'][0])/df_original.shape[0]*100:.2f}%")
    
    # 2. Data Quality Metrics
    print_subsection_header("Data Quality Improvements")
    print(f"   ‚úì Missing values handled")
    print(f"   ‚úì Duplicates removed")
    print(f"   ‚úì Outliers removed")
    print(f"   ‚úì Features encoded and scaled")
    
    # 3. Analytical Techniques Applied
    print_subsection_header("Analytical Techniques Applied")
    print(f"   1. Association Rule Mining")
    print(f"      ‚Ä¢ Frequent Itemsets: {len(frequent_itemsets) if frequent_itemsets is not None else 0}")
    print(f"      ‚Ä¢ Association Rules: {len(rules) if rules is not None else 0}")
    
    print(f"   2. Classification")
    if classification_result:
        results = classification_result['results']
        print(f"      ‚Ä¢ Models Trained: {len(results)}")
        best_model = max(results.items(), key=lambda x: x[1]['f1'])
        print(f"      ‚Ä¢ Best Model: {best_model[0]} (F1: {best_model[1]['f1']:.4f})")
    
    print(f"   3. Clustering")
    if clustering_result:
        print(f"      ‚Ä¢ Optimal Clusters: {clustering_result['optimal_k']}")
    
    # 4. Key Findings
    print_subsection_header("Key Findings")
    print(f"   ‚Ä¢ Co-purchase patterns identified through association mining")
    print(f"   ‚Ä¢ High-value customers successfully identified via classification")
    print(f"   ‚Ä¢ Customer segments with distinct behaviors identified")
    print(f"   ‚Ä¢ Multiple actionable insights for business strategy")
    
    # 5. Recommendations
    print_subsection_header("Strategic Recommendations")
    print(f"\n   1Ô∏è‚É£  PRODUCT STRATEGY")
    print(f"       ‚Ä¢ Implement product bundling based on association rules")
    print(f"       ‚Ä¢ Cross-sell and upsell strategies based on patterns")
    
    print(f"\n   2Ô∏è‚É£  CUSTOMER STRATEGY")
    print(f"       ‚Ä¢ Target high-value customers identified by classifiers")
    print(f"       ‚Ä¢ Develop segment-specific campaigns")
    print(f"       ‚Ä¢ Personalize experiences for each customer segment")
    
    print(f"\n   3Ô∏è‚É£  OPERATIONAL STRATEGY")
    print(f"       ‚Ä¢ Optimize inventory based on co-purchase patterns")
    print(f"       ‚Ä¢ Allocate marketing budget by customer segment value")
    print(f"       ‚Ä¢ Monitor and optimize predictive model performance")
    
    print(f"\n   4Ô∏è‚É£  FINANCIAL STRATEGY")
    print(f"       ‚Ä¢ Focus retention efforts on high-value segment")
    print(f"       ‚Ä¢ Increase customer lifetime value through bundling")
    print(f"       ‚Ä¢ Optimize resource allocation by segment profitability")

# ============================================================================
# CHALLENGES & LEARNINGS
# ============================================================================

def challenges_and_learnings():
    """Print challenges faced and learnings gained"""
    print_section_header("CHALLENGES & LEARNINGS")
    
    print(f"""
CHALLENGES ENCOUNTERED:

1. üî¥ Data Quality Issues
   ‚Ä¢ Missing values required careful imputation strategy
   ‚Ä¢ Duplicates needed removal without losing information
   ‚Ä¢ Outliers could skew analysis and models
   Solution: Applied domain-specific imputation, tested multiple approaches

2. üî¥ Feature Engineering
   ‚Ä¢ Diverse data types (numerical & categorical)
   ‚Ä¢ Different scales impacting distance-based algorithms
   ‚Ä¢ Feature selection for optimal model performance
   Solution: Standardized features, encoded categoricals, tested subsets

3. üî¥ Model Selection
   ‚Ä¢ Multiple classification algorithms to compare
   ‚Ä¢ Class imbalance in target variable
   ‚Ä¢ Hyperparameter tuning for optimization
   Solution: Used multiple metrics, stratified sampling, grid search

4. üî¥ Clustering Challenges
   ‚Ä¢ Determining optimal number of clusters
   ‚Ä¢ Interpreting high-dimensional cluster characteristics
   ‚Ä¢ Handling mixed data types in clustering
   Solution: Elbow method, silhouette analysis, PCA visualization

5. üî¥ Association Rules
   ‚Ä¢ Sparse itemsets with low support
   ‚Ä¢ Balancing support/confidence/lift thresholds
   ‚Ä¢ Interpreting complex associations
   Solution: Adjusted thresholds iteratively, focused on actionable rules

KEY LEARNINGS:

‚úÖ Data preprocessing is 80% of the work - quality input ensures quality output
‚úÖ Multiple evaluation metrics provide better insight than single metric
‚úÖ Visualization is crucial for communicating findings
‚úÖ Domain knowledge guides analytical decisions
‚úÖ Automation and modularity improve code maintainability
‚úÖ Always validate results with business logic
‚úÖ Document assumptions and decisions for reproducibility
    """)

# ============================================================================
# TEAM CONTRIBUTION TABLE
# ============================================================================

def team_contribution_table():
    """Display team contribution table"""
    print_section_header("TEAM CONTRIBUTION TABLE")
    
    contribution = pd.DataFrame({
        'Member': ['Your Name'],
        'Data Loading': ['100%'],
        'Preprocessing': ['100%'],
        'EDA': ['100%'],
        'Association Rules': ['100%'],
        'Classification': ['100%'],
        'Clustering': ['100%'],
        'Analysis & Insights': ['100%'],
        'Report Writing': ['100%']
    })
    
    print(contribution.to_string(index=False))

# ============================================================================
# TOOLS AND LIBRARIES USED
# ============================================================================

def tools_and_libraries():
    """List tools and libraries used"""
    print_section_header("TOOLS & LIBRARIES USED")
    
    print(f"""
PROGRAMMING LANGUAGE:
  ‚Ä¢ Python 3.x

DATA MANIPULATION & ANALYSIS:
  ‚Ä¢ pandas: Data frames and data manipulation
  ‚Ä¢ numpy: Numerical computations

VISUALIZATION:
  ‚Ä¢ matplotlib: Static plots and visualizations
  ‚Ä¢ seaborn: Enhanced statistical visualizations

MACHINE LEARNING & PREPROCESSING:
  ‚Ä¢ scikit-learn: ML algorithms and preprocessing
    - StandardScaler: Feature scaling
    - LabelEncoder: Categorical encoding
    - train_test_split: Data splitting
    - Classification models: DecisionTree, NaiveBayes, KNN
    - KMeans: Clustering algorithm
    - Metrics: Accuracy, precision, recall, F1, confusion matrix
    - PCA: Dimensionality reduction

  ‚Ä¢ mlxtend: Market basket analysis
    - apriori: Frequent itemset mining
    - association_rules: Rule generation

DEVELOPMENT ENVIRONMENT:
  ‚Ä¢ Jupyter Notebook: Interactive development and analysis

MODULES CREATED:
  ‚Ä¢ imports_setup: Configuration and utilities
  ‚Ä¢ dataset_loading: Data import and exploration
  ‚Ä¢ preprocessing: Data cleaning and transformation
  ‚Ä¢ exploratory_data_analysis: EDA and visualization
  ‚Ä¢ association_rule_mining: ARM implementation
  ‚Ä¢ classification_models: Classification algorithms
  ‚Ä¢ clustering_and_segmentation: Clustering analysis
  ‚Ä¢ business_insights_and_summary: Final analysis and recommendations
    """)

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution function"""
    print_section_header("SECTION 8: BUSINESS INSIGHTS & SUMMARY")
    
    # Load dataset
    df = load_dataset('ecommerce_customer_data_custom_ratios.csv')
    
    if df is None:
        print("Failed to load dataset")
        return
    
    # Preprocess
    preprocessing_result = preprocess_complete_pipeline(df)
    df_cleaned = preprocessing_result['dataframe']
    
    # Association Rule Mining
    frequent_itemsets, rules = perform_association_rule_mining(df_cleaned)
    
    # Classification
    classification_result = perform_classification(df_cleaned)
    
    # Clustering
    clustering_result = perform_clustering(df_cleaned)
    
    # Generate insights
    print_section_header("BUSINESS INSIGHTS")
    
    association_rule_insights(rules)
    print("\n")
    classification_insights(classification_result)
    print("\n")
    clustering_insights(clustering_result, df_cleaned)
    
    # Generate summary
    generate_summary_report(df, preprocessing_result, classification_result, 
                          clustering_result, frequent_itemsets, rules)
    
    # Challenges and learnings
    challenges_and_learnings()
    
    # Team contribution
    team_contribution_table()
    
    # Tools and libraries
    tools_and_libraries()
    
    # Final completion message
    print_section_header("PROJECT COMPLETION")
    print("""
‚úÖ ENTIRE PROJECT EXECUTED SUCCESSFULLY

All modules executed:
  ‚úì Section 1: Imports & Setup
  ‚úì Section 2: Dataset Loading
  ‚úì Section 3: Data Preprocessing
  ‚úì Section 4: Exploratory Data Analysis
  ‚úì Section 5: Association Rule Mining
  ‚úì Section 6: Classification Models
  ‚úì Section 7: Clustering & Segmentation
  ‚úì Section 8: Business Insights & Summary

üìä DELIVERABLES:
  ‚úì Comprehensive analysis completed
  ‚úì Visualizations generated
  ‚úì Models trained and evaluated
  ‚úì Insights and recommendations provided
  ‚úì Code modularized for maintainability

üéØ NEXT STEPS:
  1. Generate formal project report (PDF)
  2. Prepare presentation slides
  3. Document findings for stakeholder review
  4. Implement recommendations
    """)

if __name__ == "__main__":
    main()